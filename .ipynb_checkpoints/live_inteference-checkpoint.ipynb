{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4749fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3d6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1), # Pads the input tensor using the reflection of the input boundary\n",
    "            nn.Conv2d(in_features, in_features, 3),\n",
    "            nn.InstanceNorm2d(in_features), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_features, in_features, 3),\n",
    "            nn.InstanceNorm2d(in_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "class GeneratorResNet(nn.Module):\n",
    "    def __init__(self, input_shape, num_residual_block):\n",
    "        super(GeneratorResNet, self).__init__()\n",
    "        \n",
    "        channels = input_shape[0]\n",
    "        \n",
    "        # Initial Convolution Block\n",
    "        out_features = 64\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(channels),\n",
    "            nn.Conv2d(channels, out_features, 7),\n",
    "            nn.InstanceNorm2d(out_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        in_features = out_features\n",
    "        \n",
    "        # Downsampling\n",
    "        for _ in range(2):\n",
    "            out_features *= 2\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "        \n",
    "        # Residual blocks\n",
    "        for _ in range(num_residual_block):\n",
    "            model += [ResidualBlock(out_features)]\n",
    "            \n",
    "        # Upsampling\n",
    "        for _ in range(2):\n",
    "            out_features //= 2\n",
    "            model += [\n",
    "                nn.Upsample(scale_factor=2), # --> width*2, heigh*2\n",
    "                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            \n",
    "        # Output Layer\n",
    "        model += [nn.ReflectionPad2d(channels),\n",
    "                  nn.Conv2d(out_features, channels, 7),\n",
    "                  nn.Tanh()\n",
    "                 ]\n",
    "        \n",
    "        # Unpacking\n",
    "        self.model = nn.Sequential(*model) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c917a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneratorResNet(\n",
       "  (model): Sequential(\n",
       "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (11): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (12): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (13): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (14): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (15): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (16): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (17): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (18): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (19): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (20): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (23): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (27): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (3, 240, 200)\n",
    "n_residual_blocks = 9 \n",
    "\n",
    "G_AB = GeneratorResNet(input_shape, n_residual_blocks)\n",
    "# G_BA = GeneratorResNet(input_shape, n_residual_blocks)\n",
    "# D_A = Discriminator(input_shape)\n",
    "# D_B = Discriminator(input_shape)\n",
    "\n",
    "G_AB.load_state_dict(torch.load('model/G_AB1.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "G_AB.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "G_AB.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb50a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torchvision.transforms import ToTensor\n",
    "# live test from camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "width  = cap.get(3)  # float `width`\n",
    "height = cap.get(4)  # float `height`\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # preprocess\n",
    "    fr = cv2.resize(frame, (240,200))\n",
    "    fr = cv2.cvtColor(fr, cv2.COLOR_BGR2RGB)\n",
    "    frameTensor = ToTensor()(fr).unsqueeze(0).to(device)\n",
    "\n",
    "    # predict\n",
    "    with torch.no_grad():\n",
    "        gen_img = G_AB(frameTensor)\n",
    "\n",
    "    # postprocess\n",
    "    gen_img = gen_img.squeeze(0).cpu().numpy()\n",
    "    gen_img = (gen_img.transpose(1,2,0)+1)/2\n",
    "    gen_img = (gen_img * 255).astype(np.uint8)\n",
    "\n",
    "    # resize to original size\n",
    "    gen_img = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "    gen_img = cv2.resize(gen_img,(int(width),int(height)))\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('gen_frame', gen_img)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa98e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def split_video_into_frames(video_path, output_directory):\n",
    "    \"\"\"function that loads a video from a given path and splits it into frames\n",
    "    and saves it in the output directory\"\"\"\n",
    "    \n",
    "    video = cv2.VideoCapture(video_path) # loads the video\n",
    "\n",
    "    frame_count = 0\n",
    "    success = True\n",
    "\n",
    "    while success:\n",
    "        success, frame = video.read()# splits the video into frames\n",
    "        print(success)\n",
    "\n",
    "        if success:\n",
    "            frame_path = os.path.join(output_directory, f\"frame_{frame_count}.png\") # saves in directory\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            print(frame_path)\n",
    "\n",
    "            # Increment frame count\n",
    "            frame_count += 1\n",
    "\n",
    "    video.release()\n",
    "\n",
    "    print(f\"Split {frame_count} frames and saved them in '{output_directory}'\")\n",
    "\n",
    "    return frame_count\n",
    "\n",
    "video_path = r\"C:\\Users\\Tzach\\Desktop\\Computer Science\\Computer Vision using Deep Learning\\final project\\Video\\Tzach_test.mp4\"\n",
    "output_directory = r\"C:\\Users\\Tzach\\Desktop\\Computer Science\\Computer Vision using Deep Learning\\final project\\Video\"\n",
    "\n",
    "frame_count = split_video_into_frames(video_path, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f079d591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n",
      "C:\\Users\\Tzach\\Desktop\\Computer Science\\Computer Vision using Deep Learning\\final project\\Video\\extraction\\frame_0.png\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "through reshaping\n",
      "after model\n",
      "after sizing back\n",
      "Merged 264 images into 'C:\\Users\\Tzach\\Desktop\\Computer Science\\Computer Vision using Deep Learning\\final project\\Video\\vid.mp4'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def merge_images_to_video(image_directory, output_video_path, fps):\n",
    "    \"\"\"takes images and merges them into one video\"\"\"\n",
    "    \n",
    "    frames = [f\"frame_{i}.png\" for i in range(len(os.listdir(image_directory)))] # loads all images\n",
    "    print(len(frames))\n",
    "    first_image_path = os.path.join(image_directory, frames[0])\n",
    "    print(first_image_path)\n",
    "\n",
    "    first_image = cv2.imread(first_image_path)\n",
    "    height, width, _ = first_image.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\") #defines video format\n",
    "    video = cv2.VideoWriter(output_video_path, fourcc, fps, (240, 200)) #constructs the video class\n",
    "\n",
    "    # Merge images into video\n",
    "    for image_file in frames:\n",
    "        image_path = os.path.join(image_directory, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = TransformImageThroughModel(G_AB, image) # runs image through model\n",
    "        video.write(image)\n",
    "\n",
    "    # Release the VideoWriter\n",
    "    video.release()\n",
    "\n",
    "    print(f\"Merged {len(frames)} images into '{output_video_path}'\")\n",
    "\n",
    "merge_images_to_video(image_directory=r\"C:\\Users\\Tzach\\Desktop\\Computer Science\\Computer Vision using Deep Learning\\final project\\Video\\extraction\",\n",
    "                      output_video_path=r\"C:\\Users\\Tzach\\Desktop\\Computer Science\\Computer Vision using Deep Learning\\final project\\Video\\vid.mp4\", fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8451f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1ab90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "import cv2\n",
    "\n",
    "def TransformImageThroughModel(model, img):\n",
    "    \"\"\"takes image transforms it, sends to model, resizes and transforms back the image and returns it\"\"\"\n",
    "    img = cv2.resize(img,(240,200))\n",
    "    #faces = extract_faces(face_detector, img)\n",
    "    \n",
    "        # preprocess face\n",
    "    #original_size = (coordinates[3] - coordinates[2], coordinates[1] - coordinates[0])\n",
    "    face = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #face = cv2.resize(face,(256,256))\n",
    "    face_tensor = ToTensor()(face).unsqueeze(0).to(device)\n",
    "    print(\"through reshaping\")\n",
    "        \n",
    "        # predict\n",
    "    with torch.no_grad():\n",
    "        gen_face = model(face_tensor)\n",
    "    print(\"after model\")\n",
    "\n",
    "        # postprocess face\n",
    "    gen_face = gen_face.squeeze(0).cpu().numpy()\n",
    "    gen_face = (gen_face.transpose(1,2,0)+1)/2\n",
    "    gen_face = (gen_face * 255).astype(np.uint8)\n",
    "\n",
    "        # resize to original size\n",
    "    #gen_face = cv2.resize(gen_face, original_size)\n",
    "    gen_face = cv2.cvtColor(gen_face, cv2.COLOR_RGB2BGR)\n",
    "    print(\"after sizing back\")\n",
    "        \n",
    "        # put back in frame\n",
    "    #img[coordinates[0]:coordinates[1], coordinates[2]:coordinates[3]] = gen_face\n",
    "    return gen_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6f8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e837fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
